---
description: CLI integration patterns and command structure for rules-maker ML batch processing
globs:
  - '**/cli.py'
  - '**/commands/**'
  - '**/cli_*.py'
---
# CLI Integration Architecture

## Overview

The rules-maker CLI has been comprehensively enhanced with ML-powered batch processing capabilities, expanding from 950 to 2,235+ lines with complete integration of all ML components.

## Command Structure

### Complete CLI Command Tree
```
rules-maker
‚îú‚îÄ‚îÄ scrape                    # Enhanced single-URL scraping with ML options
‚îú‚îÄ‚îÄ batch                     # Existing basic batch processing  
‚îú‚îÄ‚îÄ ml-batch                  # ML-powered batch processing
‚îÇ   ‚îú‚îÄ‚îÄ frameworks            # Process popular frameworks (React, Vue, Angular, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ cloud                 # Process cloud platforms (AWS, Azure, GCP)
‚îÇ   ‚îî‚îÄ‚îÄ custom                # Custom source lists with JSON input
‚îú‚îÄ‚îÄ ml                        # Existing ML training commands
‚îú‚îÄ‚îÄ learning                  # Integrated learning system
‚îÇ   ‚îú‚îÄ‚îÄ feedback              # Collect feedback signals for rules
‚îÇ   ‚îî‚îÄ‚îÄ analyze               # Analyze learning patterns and performance
‚îú‚îÄ‚îÄ quality                   # Quality assessment commands
‚îÇ   ‚îú‚îÄ‚îÄ assess                # Assess rule quality with ML scoring
‚îÇ   ‚îî‚îÄ‚îÄ cluster               # Analyze rule clusters and coherence
‚îú‚îÄ‚îÄ analytics                 # Analytics and insights
‚îÇ   ‚îî‚îÄ‚îÄ insights              # Generate comprehensive processing insights
‚îú‚îÄ‚îÄ bedrock                   # Enhanced Bedrock operations
‚îÇ   ‚îú‚îÄ‚îÄ validate              # Existing validation functionality
‚îÇ   ‚îî‚îÄ‚îÄ batch                 # Bedrock batch processing with cost monitoring
‚îî‚îÄ‚îÄ config                    # Configuration management
    ‚îú‚îÄ‚îÄ init                  # Initialize ML configuration from templates
    ‚îî‚îÄ‚îÄ validate              # Validate YAML configuration files
```

## ML Batch Commands

### ml-batch frameworks
Process popular web frameworks with ML enhancement:

```bash
# Process popular frameworks
rules-maker ml-batch frameworks --output rules/frameworks --bedrock

# With quality threshold and clustering
rules-maker ml-batch frameworks --quality-threshold 0.7 --enable-clustering

# Dry run for testing
rules-maker ml-batch frameworks --dry-run --config config/ml_batch_config.yaml
```

**Supported Frameworks**:
- React, Vue.js, Angular, Next.js, Nuxt.js
- Svelte, Solid, Preact, Alpine.js
- Express.js, Fastify, Koa, NestJS
- Django, Flask, FastAPI, Pyramid

### ml-batch cloud
Process cloud platform documentation:

```bash
# Process cloud platforms
rules-maker ml-batch cloud --output rules/cloud --bedrock

# With specific platforms
rules-maker ml-batch cloud --platforms aws,azure,gcp --max-concurrent 10
```

**Supported Platforms**:
- AWS (EC2, S3, Lambda, API Gateway, etc.)
- Azure (Functions, Storage, App Service, etc.)
- Google Cloud (Cloud Functions, Storage, Compute, etc.)

### ml-batch custom
Process custom source lists with JSON input:

```bash
# Process custom sources
rules-maker ml-batch custom --sources custom_sources.json --output rules/custom

# With Bedrock integration and cost monitoring
rules-maker ml-batch custom --bedrock --max-daily-cost 5.0
```

## Learning System Commands

### learning feedback
Collect feedback signals for rule improvement:

```bash
# Collect usage feedback
rules-maker learning feedback --rule-id "rule_123" --signal-type "usage_success" --value 0.8

# With context metadata
rules-maker learning feedback --rule-id "rule_123" --signal-type "user_rating" --value 0.9 --context '{"user_id": "user_456", "session_id": "session_789"}'
```

**Supported Signal Types**:
- `usage_success`: Rule usage success rate (0.0-1.0)
- `user_rating`: User satisfaction rating (0.0-1.0)
- `effectiveness`: Rule effectiveness score (0.0-1.0)
- `relevance`: Content relevance score (0.0-1.0)

### learning analyze
Analyze learning patterns and performance:

```bash
# Analyze learning patterns
rules-maker learning analyze --output analysis_report.json

# With time range filtering
rules-maker learning analyze --start-date 2024-01-01 --end-date 2024-12-31
```

## Quality Assessment Commands

### quality assess
Assess rule quality using ML-powered scoring:

```bash
# Assess rule quality
rules-maker quality assess --input rules/ --format cursor --output quality_report.json

# With quality threshold
rules-maker quality assess --input rules/ --quality-threshold 0.7 --format all
```

**Supported Formats**:
- `cursor`: Cursor rules only
- `windsurf`: Windsurf rules only
- `all`: All rule formats

### quality cluster
Analyze rule clusters and coherence:

```bash
# Analyze rule clusters
rules-maker quality cluster --input rules/ --output cluster_analysis.json

# With coherence threshold
rules-maker quality cluster --input rules/ --coherence-threshold 0.6 --format yaml
```

## Analytics Commands

### analytics insights
Generate comprehensive processing insights:

```bash
# Generate insights
rules-maker analytics insights --input rules/ --output insights_report.json

# With multiple output formats
rules-maker analytics insights --input rules/ --format json,yaml,markdown
```

**Insights Generated**:
- Processing results analysis with detailed metrics
- Technology distribution analysis and cluster insights
- Quality metrics and performance statistics
- Rule effectiveness and usage patterns

## Configuration Commands

### config init
Initialize ML configuration from templates:

```bash
# Initialize minimal configuration
rules-maker config init --template minimal --output config/ml_config.yaml

# Initialize standard configuration
rules-maker config init --template standard --output config/ml_config.yaml

# Initialize advanced configuration
rules-maker config init --template advanced --output config/ml_config.yaml
```

**Available Templates**:
- `minimal`: Basic configuration with essential settings
- `standard`: Complete configuration matching ml_batch_config.yaml
- `advanced`: Extended configuration with experimental features

### config validate
Validate YAML configuration files:

```bash
# Validate configuration
rules-maker config validate --config config/ml_config.yaml

# Validate with detailed output
rules-maker config validate --config config/ml_config.yaml --verbose
```

## Enhanced Existing Commands

### Enhanced scrape Command
The existing `scrape` command has been enhanced with ML capabilities:

```bash
# Standard scraping (unchanged)
rules-maker scrape https://docs.example.com --output rules/

# With ML enhancement
rules-maker scrape https://docs.example.com --ml-enhanced --quality-assessment

# With learning feedback collection
rules-maker scrape https://docs.example.com --learning-feedback --output rules/
```

**New Options**:
- `--ml-enhanced`: Enables ML-enhanced processing pipeline
- `--quality-assessment`: Includes quality assessment in rule output
- `--learning-feedback`: Collects learning feedback signals during processing

### Enhanced bedrock Commands
The existing `bedrock` command group has been enhanced:

```bash
# Existing validation (unchanged)
rules-maker bedrock validate

# New batch processing
rules-maker bedrock batch --sources sources.json --max-cost 10.0

# With specific model and region
rules-maker bedrock batch --model amazon.nova-lite-v1:0 --region us-east-1
```

## Configuration Integration

### Configuration Loading
The CLI automatically loads configuration from multiple sources:

```python
# Configuration loading priority
1. Command line options (highest priority)
2. --config file specified
3. config/ml_batch_config.yaml (default)
4. Built-in defaults (lowest priority)
```

### Configuration Templates

#### Minimal Template
```yaml
batch_processing:
  max_concurrent: 5
  output_format: [cursor]
  quality_threshold: 0.6
bedrock_integration:
  model_id: amazon.nova-lite-v1:0
  region: us-east-1
  temperature: 0.3
ml_engine:
  enable_self_improvement: false
  quality_threshold: 0.6
```

#### Standard Template
```yaml
batch_processing:
  max_concurrent: 15
  quality_threshold: 0.7
  enable_clustering: true
  coherence_threshold: 0.6
ml_engine:
  quality_threshold: 0.7
  enable_self_improvement: true
  clustering_algorithm: "kmeans"
integrated_learning:
  enable_ml: true
  ml_weight: 0.6
  feedback_integration: true
```

## Error Handling and Graceful Degradation

### ML Dependency Fallbacks
The CLI includes comprehensive fallback handling:

```python
# Graceful degradation when ML dependencies unavailable
try:
    from .batch_processor import MLBatchProcessor
    ML_FEATURES_AVAILABLE = True
except ImportError as e:
    ML_FEATURES_AVAILABLE = False
    click.echo(f"‚ö†Ô∏è ML features not available: {e}", err=True)
```

### Error Messages
Clear, actionable error messages for common issues:

```bash
# Missing ML dependencies
‚ö†Ô∏è ML features not available: No module named 'sklearn'

# Invalid configuration
‚ùå Configuration validation failed: Invalid quality_threshold value

# Missing files
‚ùå Input directory not found: rules/
```

## Progress Tracking

### Real-time Progress Updates
Comprehensive progress tracking for all operations:

```bash
# Batch processing progress
üîÑ Processing sources... [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% (15/15)
‚úÖ Processed 15 sources in 2m 34s
üìä Generated 45 rules with average quality: 0.78
üí∞ Estimated cost: $2.34

# Quality assessment progress
üîÑ Assessing rule quality... [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% (45/45)
‚úÖ Assessed 45 rules in 12s
üìä Average quality score: 0.78
üéØ High quality rules: 32 (71%)
```

## Testing and Validation

### Integration Tests
Comprehensive test suite covering all functionality:

```bash
# Test ML integration
PYTHONPATH=src pytest tests/test_cli_ml_integration.py -v

# Test specific command groups
PYTHONPATH=src pytest tests/test_cli_ml_integration.py::test_ml_batch_commands -v
PYTHONPATH=src pytest tests/test_cli_ml_integration.py::test_learning_commands -v
```

### Dry Run Mode
Safe testing without actual processing:

```bash
# Test configuration without processing
rules-maker ml-batch frameworks --dry-run --config config/ml_config.yaml

# Test Bedrock integration without API calls
rules-maker bedrock batch --dry-run --sources sources.json
```

## Performance Characteristics

### CLI Performance
- **Startup time**: <1 second
- **Command parsing**: <100ms
- **Configuration loading**: <200ms
- **Help generation**: <500ms

### Memory Usage
- **Base CLI**: ~50MB
- **With ML features**: ~200MB
- **Batch processing**: Scales with batch size

## Best Practices

### 1. Configuration Management
- Use `config init` to create proper configuration files
- Validate configurations before processing
- Use templates appropriate for your use case

### 2. Error Handling
- Always check for ML feature availability
- Use dry run mode for testing
- Monitor progress and handle interruptions gracefully

### 3. Performance Optimization
- Use appropriate batch sizes for your system
- Monitor memory usage during large operations
- Use quality thresholds to filter results

### 4. Cost Management
- Set appropriate daily spending limits for Bedrock
- Monitor costs during batch processing
- Use dry run mode to estimate costs