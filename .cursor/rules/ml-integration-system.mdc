---
description: ML integration system architecture and capabilities for rules-maker scrapers and transformers
globs:
  - '**/ml_*.py'
  - '**/batch_processor.py'
  - '**/learning/**'
  - '**/strategies/**'
  - '**/transformers/ml_*.py'
---
# ML Integration System Architecture

## Overview

The rules-maker project includes a comprehensive ML-powered batch processing system that enhances scrapers and rule transformers with intelligent clustering, self-improving feedback loops, and quality optimization.

## Core ML Components

### 1. ML-Enhanced Processors
**Location**: `src/rules_maker/processors/ml_documentation_processor.py`

```python
from rules_maker.processors.ml_documentation_processor import MLDocumentationProcessor

# Initialize with ML semantic analysis
processor = MLDocumentationProcessor()

# Process content with ML enhancement
result = processor.process(html_content, url, metadata)

# Access ML insights
print(f"ML Enhanced: {result.metadata['ml_enhanced']}")
print(f"Semantic Keywords: {result.metadata['semantic_keywords']}")
print(f"Content Complexity: {result.metadata['content_complexity']}")
```

**Features**:
- Extends existing DocumentationProcessor
- Semantic keyword extraction  
- Technology stack detection
- Content complexity scoring
- Graceful degradation on ML failure

### 2. ML Learning Strategies
**Location**: `src/rules_maker/strategies/ml_quality_strategy.py`

```python
from rules_maker.strategies.ml_quality_strategy import MLQualityStrategy

# Initialize ML strategy
strategy = MLQualityStrategy(config={'quality_threshold': 0.7})

# Train with feedback data
performance = await strategy.train(training_set)

# Predict rule quality
prediction = await strategy.predict(rule_content, url)
print(f"Quality Score: {prediction['quality_score']}")
print(f"Recommendations: {prediction['recommendations']}")
```

**Features**:
- RandomForest classifier for quality prediction
- GradientBoosting regressor for quality scoring
- TF-IDF vectorization for semantic analysis
- Model persistence and loading
- Heuristic fallback when models aren't trained

### 3. ML-Enhanced Transformers
**Location**: `src/rules_maker/transformers/ml_cursor_transformer.py`

```python
from rules_maker.transformers.ml_cursor_transformer import MLCursorTransformer

# Initialize with ML configuration
transformer = MLCursorTransformer(ml_config={
    'quality_threshold': 0.7,
    'enable_clustering': True,
    'coherence_threshold': 0.6
})

# Transform with ML enhancement
enhanced_rules = transformer.transform(scraping_results)
```

**Features**:
- Extends existing CursorRuleTransformer
- ML quality assessment section
- Intelligent rule clustering
- Self-improving feedback integration
- Source quality breakdown
- Quality recommendations

### 4. Integrated Learning System
**Location**: `src/rules_maker/learning/integrated_learning_system.py`

```python
from rules_maker.learning.integrated_learning_system import IntegratedLearningSystem

# Initialize integrated system
system = IntegratedLearningSystem(config={
    'ml_weight': 0.6,  # 60% ML, 40% base engine
    'feedback_integration': True
})

# Combined learning and improvement
optimized_rules = await system.learn_and_improve(rules, usage_data)

# Get performance statistics
stats = await system.get_system_performance_stats()
```

**Features**:
- Combines existing LearningEngine with SelfImprovingEngine
- Weighted integration of base and ML predictions
- Feedback signal collection and processing
- System performance monitoring
- Configurable ML vs base engine weighting

### 5. ML Batch Processor
**Location**: `src/rules_maker/batch_processor.py`

```python
from rules_maker.batch_processor import MLBatchProcessor, DocumentationSource

# Initialize batch processor
processor = MLBatchProcessor(
    output_dir="rules/ml_batch",
    quality_threshold=0.7,
    max_concurrent=15
)

# Process documentation sources
sources = [
    DocumentationSource("https://reactjs.org/docs/", "React", "javascript", "react", priority=5),
    # ... more sources
]

result = await processor.process_documentation_batch(sources)
```

**Features**:
- Intelligent batch processing with clustering
- Quality-aware source filtering
- Concurrent processing with rate limiting
- Progress tracking and result reporting
- Integration with Bedrock for LLM processing

## Integration Patterns

### Backward Compatibility
All existing functionality remains fully functional:

```python
# Existing code continues to work unchanged
from rules_maker.transformers.cursor_transformer import CursorRuleTransformer
from rules_maker.scrapers.async_documentation_scraper import AsyncDocumentationScraper

# Still works exactly as before
scraper = AsyncDocumentationScraper()
transformer = CursorRuleTransformer()

results = await scraper.scrape_documentation_site("https://docs.example.com")
rules = transformer.transform(results)
```

### Progressive Enhancement
ML components provide optional enhancement:

```python
# Standard processor
from rules_maker.processors.documentation_processor import DocumentationProcessor
processor = DocumentationProcessor()

# ML-enhanced processor (drop-in replacement)
from rules_maker.processors.ml_documentation_processor import MLDocumentationProcessor  
ml_processor = MLDocumentationProcessor()

# Both work identically, ML version adds semantic analysis
result = ml_processor.process(content, url, metadata)
```

## Configuration System

### ML Batch Configuration
**Location**: `config/ml_batch_config.yaml`

```yaml
batch_processing:
  max_concurrent: 15
  quality_threshold: 0.7
  enable_clustering: true
  coherence_threshold: 0.6

ml_engine:
  quality_threshold: 0.7
  enable_self_improvement: true
  clustering_algorithm: "kmeans"
  model_directory: "models/"

integrated_learning:
  enable_ml: true
  ml_weight: 0.6
  feedback_integration: true

bedrock_integration:
  model_id: "amazon.nova-lite-v1:0"
  region: "us-east-1"
  temperature: 0.3
```

## CLI Integration

The ML system is fully integrated into the CLI with comprehensive command groups:

```bash
# ML Batch Processing
rules-maker ml-batch frameworks    # Process popular frameworks
rules-maker ml-batch cloud         # Process cloud platforms  
rules-maker ml-batch custom        # Custom source processing

# Learning System
rules-maker learning feedback      # Collect feedback signals
rules-maker learning analyze       # Analyze learning patterns

# Quality Assessment
rules-maker quality assess         # Assess rule quality
rules-maker quality cluster        # Analyze rule clusters

# Analytics
rules-maker analytics insights     # Generate processing insights

# Configuration
rules-maker config init           # Initialize ML config
rules-maker config validate       # Validate configuration
```

## Usage Examples

### Basic ML Enhancement
```python
# Standard processor
from rules_maker.processors.documentation_processor import DocumentationProcessor
processor = DocumentationProcessor()

# ML-enhanced processor (drop-in replacement)
from rules_maker.processors.ml_documentation_processor import MLDocumentationProcessor  
ml_processor = MLDocumentationProcessor()

# Both work identically, ML version adds semantic analysis
result = ml_processor.process(content, url, metadata)
```

### Quality-Aware Rule Generation
```python
from rules_maker.transformers.ml_cursor_transformer import MLCursorTransformer

# Configure ML enhancement
ml_config = {
    'quality_threshold': 0.7,
    'enable_clustering': True,
    'coherence_threshold': 0.6
}

transformer = MLCursorTransformer(ml_config=ml_config)
rules = transformer.transform(scraping_results)

# Rules now include ML quality assessment
print("ML Quality Assessment" in rules)  # True
```

### Integrated Learning
```python
from rules_maker.learning.integrated_learning_system import IntegratedLearningSystem

system = IntegratedLearningSystem({
    'ml_weight': 0.6,      # Prefer ML insights
    'enable_ml': True,
    'feedback_integration': True
})

# Combines base engine + ML engine insights
optimized = await system.learn_and_improve(rules, usage_events)
print(f"Quality improved to: {optimized.quality_score:.3f}")
```

## Performance Characteristics

### Memory Usage
- **Base system**: ~500MB for 10 sources
- **ML-enhanced**: ~2-4GB for 100 sources (with clustering)
- **Optimization**: Configurable quality thresholds reduce memory usage

### Processing Speed
- **ML overhead**: ~20-30% additional processing time
- **Clustering benefit**: 5x throughput improvement for large batches
- **Quality prediction**: <100ms per rule prediction

### Quality Improvements
- **Semantic analysis**: Enhanced technology detection accuracy
- **Quality scoring**: Automated rule effectiveness prediction
- **Self-improvement**: Continuous optimization based on usage feedback

## Dependencies

### Required ML Dependencies
```bash
scikit-learn>=1.3.0
numpy>=1.24.0
```

### Graceful Degradation
The system includes comprehensive fallback handling:
- Commands work even when ML dependencies unavailable
- Clear error messages when ML features not available
- Automatic fallback to base functionality

## Testing

### Test Coverage
```bash
# Test ML integration
PYTHONPATH=src pytest tests/test_ml_integration.py -v

# Test existing functionality (should still pass)
PYTHONPATH=src pytest tests/test_phase1.py -v
PYTHONPATH=src pytest tests/test_transformers.py -v
```

### Health Checks
```python
# Check ML component health
from rules_maker.learning.integrated_learning_system import IntegratedLearningSystem

system = IntegratedLearningSystem()
stats = await system.get_system_performance_stats()
print(f"ML Status: {stats['components']['ml_engine']}")
```

## Key Integration Points

### Existing Component Enhancement

| Existing Component | ML Enhancement | Integration Method |
|-------------------|----------------|-------------------|
| `DocumentationProcessor` | `MLDocumentationProcessor` | Inheritance + composition |
| `CursorRuleTransformer` | `MLCursorTransformer` | Inheritance + async enhancement |
| `LearningEngine` | `IntegratedLearningSystem` | Composition + weighted combination |
| `LearningStrategy` | `MLQualityStrategy` | Strategy pattern implementation |
| Batch processing | Enhanced with clustering | Existing MLBatchProcessor |

### Backward Compatibility
✅ **All existing APIs remain functional**
- Existing processors, transformers, and learning components work unchanged
- ML components provide optional enhancement
- Graceful degradation when ML components fail
- Configuration-driven ML feature enablement