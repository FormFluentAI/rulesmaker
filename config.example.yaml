# Rules Maker Configuration

## Scraping Configuration
scraping:
  max_depth: 3
  max_pages: 100
  timeout: 30
  delay: 1.0
  user_agent: "RulesMaker/0.1.0"
  follow_links: true
  respect_robots_txt: true
  rate_limit: 1.0
  javascript_enabled: true

## Transformation Configuration
transformation:
  rule_format: "cursor"
  template_name: "default"
  max_rules: 50
  include_examples: true
  include_metadata: true
  custom_instructions: ""

## Output Configuration
output:
  format_rules: true
  include_metadata: true
  output_directory: "./output"

## Filter Configuration
filters:
  min_content_length: 100
  exclude_patterns:
    - "404"
    - "not found"
    - "error"
  include_patterns:
    - "documentation"
    - "api"
    - "guide"

## Bedrock Configuration
bedrock:
  # Default Bedrock model and region
  model_id: "amazon.nova-lite-v1:0"
  region: "us-east-1"

  # Optional path to a CSV containing long-term credentials for Bedrock
  # See docs/plans/bedrock-long-term-api-key.csv for an example format
  credentials_csv: ""

  # LLM request behavior
  timeout: 30            # seconds (connect/read)
  concurrency: 4         # max concurrent Bedrock LLM calls

  # Retry/backoff policy for throttling and transient errors
  retry:
    max_attempts: 5      # total attempts (initial + retries)
    base_ms: 200         # base backoff in milliseconds
    max_ms: 4000         # max backoff in milliseconds

  # Fallback when Bedrock is unavailable
  fallback:
    enabled: false
    # Order to try when Bedrock fails: any of [openai, anthropic, huggingface, local]
    providers:
      - openai

## Optional multi-provider settings (used by fallback)
providers:
  openai:
    api_key: ""           # or env OPENAI_API_KEY
    model: "gpt-4o-mini"
  anthropic:
    api_key: ""           # or env ANTHROPIC_API_KEY
    model: "claude-3-haiku-20240307"
  huggingface:
    api_key: ""           # or env HUGGINGFACE_API_KEY
    model: "meta-llama/Meta-Llama-3-8B-Instruct"
  local:
    base_url: ""          # e.g., http://localhost:11434
    model: "qwen2.5:14b"

## Telemetry and Logging
telemetry:
  json: false            # emit JSON structured logs when true
  redact_prompts: true   # do not log prompt content; log hash + length only

## Caching and Budgets
cache:
  enabled: false
  dir: ""                 # default: ~/.cache/rules_maker/llm
budget:
  hourly_usd: null        # e.g., 0.50 blocks calls after $0.50 in the last hour
  daily_usd: null         # e.g., 2.00 blocks calls after $2.00 in the last day
